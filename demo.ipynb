{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sparse Autoencoder Training Demo"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Autoreload\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sparse_autoencoder import TensorActivationStore, SparseAutoencoder\n",
                "from sparse_autoencoder.train.pipeline import pipeline\n",
                "from sparse_autoencoder.source_data.pile_uncopyrighted import PileUncopyrightedDataset\n",
                "from transformer_lens import HookedTransformer\n",
                "from transformer_lens.utils import get_device\n",
                "from transformers import GPT2TokenizerFast\n",
                "import torch\n",
                "import wandb"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1.13.1+cu117\n"
                    ]
                }
            ],
            "source": [
                "print(torch.__version__)\n",
                "device = get_device()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "db66b4678e66406bbb23a7e5e69e8d68",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
                "source_data = PileUncopyrightedDataset(tokenizer=tokenizer)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5a42f740944d4d389e04feeb02d206f3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "(…)_1L512W_C4_Code/resolve/main/config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "de6e02ccae384648a5dcdc6ecde0d128",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model_final.pth:   0%|          | 0.00/213M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "752ebfcbd6eb4b2c96c1746ebde173a3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "(…)igits/resolve/main/tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "257691ab5f1a4a3393b014a6a32ae0ec",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "(…)nizer-digits/resolve/main/tokenizer.json:   0%|          | 0.00/2.04M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e6cbce2aadc647f5bac342b7d28f1182",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "(…)its/resolve/main/special_tokens_map.json:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded pretrained model solu-1l into HookedTransformer\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "2048"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "src_model = HookedTransformer.from_pretrained(\"solu-1l\", dtype=\"float32\")\n",
                "src_d_mlp = src_model.cfg.d_mlp\n",
                "src_d_mlp"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Activation Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_items = 2_000_000\n",
                "store = TensorActivationStore(max_items, src_d_mlp, device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'create_src_dataloader' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m src_dataloader \u001b[39m=\u001b[39m create_src_dataloader(\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mNeelNanda/c4-code-tokenized-2b\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     collate_fn\u001b[39m=\u001b[39mcollate_neel_c4_tokenized,\n\u001b[1;32m      4\u001b[0m     shuffle_buffer_size\u001b[39m=\u001b[39m\u001b[39m10_000\u001b[39m,\n\u001b[1;32m      5\u001b[0m     random_seed\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'create_src_dataloader' is not defined"
                    ]
                }
            ],
            "source": [
                "src_dataloader = create_src_dataloader(\n",
                "    \"NeelNanda/c4-code-tokenized-2b\",\n",
                "    collate_fn=collate_neel_c4_tokenized,\n",
                "    shuffle_buffer_size=10_000,\n",
                "    random_seed=0,\n",
                "    batch_size=64,\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "SparseAutoencoder(\n",
                            "  (encoder): Sequential(\n",
                            "    (0): TiedBias(position=pre_encoder)\n",
                            "    (1): ConstrainedUnitNormLinear(in_features=2048, out_features=16384, bias=True)\n",
                            "    (2): ReLU()\n",
                            "  )\n",
                            "  (decoder): Sequential(\n",
                            "    (0): ConstrainedUnitNormLinear(in_features=16384, out_features=2048, bias=False)\n",
                            "    (1): TiedBias(position=post_decoder)\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "autoencoder = SparseAutoencoder(src_d_mlp, src_d_mlp * 8, torch.zeros(src_d_mlp))\n",
                "autoencoder"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you initialise [wandb](https://wandb.ai/site), the pipeline will automatically log all metrics to wandb."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7efdcc84f010>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7efd505df9a0, raw_cell=\"wandb.init(project=\"sae\", name=\"Alan_Run_2\", dir=\"..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2Bvast_cold/root/sparse_autoencoder/demo.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D>,),kwargs {}:\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path .cache/wandb/wandb/ wasn't writable, using system temp directory.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "Finishing last run (ID:tk9j6iu0) before initializing another..."
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6faf974c352942578b60a59bef2e6b23",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "VBox(children=(Label(value='0.021 MB of 0.021 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run <strong style=\"color:#cdcd00\">Alan_Run_2</strong> at: <a href='https://wandb.ai/arthurconmy/sae/runs/tk9j6iu0' target=\"_blank\">https://wandb.ai/arthurconmy/sae/runs/tk9j6iu0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Find logs at: <code>./wandb/run-20231107_123801-tk9j6iu0/logs</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Successfully finished last run (ID:tk9j6iu0). Initializing new run:<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "wandb: WARNING Path .cache/wandb/wandb/ wasn't writable, using system temp directory\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "735cc63958294a54bd27cf0dc556c47c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113747995760705, max=1.0…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.15.12"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/tmp/wandb/run-20231107_123819-ixhby9r2</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/arthurconmy/sae/runs/ixhby9r2' target=\"_blank\">Alan_Run_2</a></strong> to <a href='https://wandb.ai/arthurconmy/sae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/arthurconmy/sae' target=\"_blank\">https://wandb.ai/arthurconmy/sae</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/arthurconmy/sae/runs/ixhby9r2' target=\"_blank\">https://wandb.ai/arthurconmy/sae/runs/ixhby9r2</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/arthurconmy/sae/runs/ixhby9r2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
                        ],
                        "text/plain": [
                            "<wandb.sdk.wandb_run.Run at 0x7efd505c2620>"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "wandb.init(project=\"sae\", name=\"Alan_Run_2\", dir=\".cache/wandb\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f5717fe2626f4f208fd32ece3e170f7a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generate/Train Cycles: 0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Token indices sequence length is longer than the specified maximum sequence length for this model (3180 > 1024). Running this sequence through the model will result in indexing errors\n"
                    ]
                },
                {
                    "ename": "AttributeError",
                    "evalue": "'dict' object has no attribute 'shape'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline(\n\u001b[1;32m      2\u001b[0m     src_model\u001b[39m=\u001b[39;49msrc_model,\n\u001b[1;32m      3\u001b[0m     src_model_activation_hook_point\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mblocks.0.mlp.hook_post\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     src_model_activation_layer\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     src_dataloader\u001b[39m=\u001b[39;49msource_data,\n\u001b[1;32m      6\u001b[0m     activation_store\u001b[39m=\u001b[39;49mstore,\n\u001b[1;32m      7\u001b[0m     num_activations_before_training\u001b[39m=\u001b[39;49mmax_items,\n\u001b[1;32m      8\u001b[0m     autoencoder\u001b[39m=\u001b[39;49mautoencoder,\n\u001b[1;32m      9\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     10\u001b[0m )\n",
                        "File \u001b[0;32m~/sparse_autoencoder/sparse_autoencoder/train/pipeline.py:67\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(src_model, src_model_activation_hook_point, src_model_activation_layer, src_dataloader, activation_store, num_activations_before_training, autoencoder, sweep_parameters, device)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m logging_redirect_tqdm(), tqdm(\n\u001b[1;32m     61\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerate/Train Cycles\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m     position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     63\u001b[0m     dynamic_ncols\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     64\u001b[0m ) \u001b[39mas\u001b[39;00m progress_bar:\n\u001b[1;32m     65\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m         \u001b[39m# Add activations to the store\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m         generate_activations(\n\u001b[1;32m     68\u001b[0m             src_model,\n\u001b[1;32m     69\u001b[0m             src_model_activation_layer,\n\u001b[1;32m     70\u001b[0m             src_model_activation_hook_point,\n\u001b[1;32m     71\u001b[0m             activation_store,\n\u001b[1;32m     72\u001b[0m             src_dataloader,\n\u001b[1;32m     73\u001b[0m             device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     74\u001b[0m             num_items\u001b[39m=\u001b[39;49mnum_activations_before_training,\n\u001b[1;32m     75\u001b[0m         )\n\u001b[1;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(activation_store) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     77\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
                        "File \u001b[0;32m~/sparse_autoencoder/sparse_autoencoder/train/generate_activations.py:66\u001b[0m, in \u001b[0;36mgenerate_activations\u001b[0;34m(model, layer, cache_name, store, dataloader, num_items, device)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m# Get the input dimensions for logging\u001b[39;00m\n\u001b[1;32m     65\u001b[0m first_item: Int[Tensor, \u001b[39m\"\u001b[39m\u001b[39mbatch pos\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataloader))\n\u001b[0;32m---> 66\u001b[0m batch_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m first_item\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m context_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m first_item\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     68\u001b[0m activations_per_batch: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m context_size \u001b[39m*\u001b[39m batch_size\n",
                        "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
                    ]
                }
            ],
            "source": [
                "pipeline(\n",
                "    src_model=src_model,\n",
                "    src_model_activation_hook_point=\"blocks.0.mlp.hook_post\",\n",
                "    src_model_activation_layer=0,\n",
                "    src_dataloader=source_data,\n",
                "    activation_store=store,\n",
                "    num_activations_before_training=max_items,\n",
                "    autoencoder=autoencoder,\n",
                "    device=device,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([250])"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a = next(iter(source_data))\n",
                "torch.LongTensor(a[\"input_ids\"]).shape"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
