{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sparse Autoencoder Training Demo"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Autoreload\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sparse_autoencoder import TensorActivationStore, SparseAutoencoder\n",
                "from sparse_autoencoder.source_data.pile_uncopyrighted import PileUncopyrightedDataset\n",
                "from transformer_lens import HookedTransformer\n",
                "from transformer_lens.utils import get_device\n",
                "from transformers import GPT2TokenizerFast\n",
                "import torch\n",
                "import wandb"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1.13.1+cu117\n"
                    ]
                }
            ],
            "source": [
                "print(torch.__version__)\n",
                "device = get_device()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "963aec2b91ee42e4b8dc8fb1288219a3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "(…)gingface.co/gpt2/resolve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "38a94244f2dc4098b675cd414cdfcb7b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "(…)gingface.co/gpt2/resolve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3ee040b6c6d04dc5a862031447b2b7c7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "(…)face.co/gpt2/resolve/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2ec01233e71f406c9750e7682f3f9a34",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "(…)ingface.co/gpt2/resolve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c02d296d46234744be5daf02b898b6ac",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading readme:   0%|          | 0.00/776 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "32636575a8b442f0939e72e4a61d18c9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
                "source_data = PileUncopyrightedDataset(tokenizer=tokenizer)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Source Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded pretrained model solu-1l into HookedTransformer\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "2048"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "src_model = HookedTransformer.from_pretrained(\"solu-1l\", dtype=\"float32\")\n",
                "src_d_mlp = src_model.cfg.d_mlp\n",
                "src_d_mlp"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Activation Store"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_items = 2_000_000\n",
                "store = TensorActivationStore(max_items, src_d_mlp, device)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Autoencoder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "SparseAutoencoder(\n",
                            "  (encoder): Sequential(\n",
                            "    (0): TiedBias(position=TiedBiasPosition.PRE_ENCODER)\n",
                            "    (1): ConstrainedUnitNormLinear(in_features=2048, out_features=16384, bias=True)\n",
                            "    (2): ReLU()\n",
                            "  )\n",
                            "  (decoder): Sequential(\n",
                            "    (0): ConstrainedUnitNormLinear(in_features=16384, out_features=2048, bias=False)\n",
                            "    (1): TiedBias(position=TiedBiasPosition.POST_DECODER)\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "autoencoder = SparseAutoencoder(src_d_mlp, src_d_mlp * 8, torch.zeros(src_d_mlp))\n",
                "autoencoder"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you initialise [wandb](https://wandb.ai/site), the pipeline will automatically log all metrics to wandb."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# wandb.init(project=\"sparse-autoencoder\", dir=\".cache/wandb\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# pipeline(\n",
                "#     src_model=src_model,\n",
                "#     src_model_activation_hook_point=\"blocks.0.mlp.hook_post\",\n",
                "#     src_model_activation_layer=0,\n",
                "#     src_dataloader=src_dataloader,\n",
                "#     activation_store=store,\n",
                "#     num_activations_before_training=max_items,\n",
                "#     autoencoder=autoencoder,\n",
                "#     device=device,\n",
                "# )"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
